{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f537dd43-d39c-471b-a54e-07f1c3ddb66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmcam\\.venv-tts\\lib\\site-packages\\librosa\\core\\intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "import IPython.display as ipd\n",
    "\n",
    "import re, yaml, numpy as np, tiktoken\n",
    "import ollama\n",
    "import os, json\n",
    "import os, sys\n",
    "import psycopg\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813abd7e-5309-44c9-b186-b303ce069216",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = \"nomic-embed-text\"\n",
    "LLM = \"gemma3:4b\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an AI Oral Board Examiner. Answer concisely and clinically. \n",
    "Use the provided CONTEXT. If uncertain, say so.\"\"\"\n",
    "\n",
    "SYSTEM_EXAMINER = \"\"\"You are the EXAMINER in a surgical oral boards simulation.\n",
    "Follow the rules from the basecase.md file\n",
    "\"\"\"\n",
    "\n",
    "BASE_PATH = Path.home() / \"OneDrive/Desktop/SoftwareDocuments/baseCase.md\"\n",
    "BASE_MD = Path(\"C:\\\\Users\\\\jmcam\\\\OneDrive\\\\Desktop\\\\SoftwareDocuments\\\\baseCase.md\").read_text(encoding=\"utf-8\")\n",
    "doc_text = BASE_MD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a6c2f01-6802-4891-9d0b-a5688420c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "def tokens(s): return len(enc.encode(s))\n",
    "\n",
    "def split_by_headings(md: str):\n",
    "    parts = re.split(r\"(?m)^##\\s+|^###\\s+\", md)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "#Makes chunks <= max_tokens with a 50 overlap so context is not lost\n",
    "def smart_chunk(md: str, max_tokens=500, overlap=50):\n",
    "    raw = split_by_headings(md)\n",
    "    chunks = []\n",
    "    for part in raw:\n",
    "        if tokens(part) <= max_tokens:\n",
    "            chunks.append(part)\n",
    "        else:\n",
    "            words = part.split()\n",
    "            cur, cur_tokens = [], 0\n",
    "            for w in words:\n",
    "                tw = tokens(w + \" \")\n",
    "                if cur_tokens + tw > max_tokens:\n",
    "                    chunks.append(\" \".join(cur))\n",
    "                    # token-overlap to preserve context at boundaries\n",
    "                    back = enc.decode(enc.encode(\" \".join(cur))[-overlap:])\n",
    "                    cur = back.split() if back else []\n",
    "                    cur_tokens = tokens(\" \".join(cur))\n",
    "                cur.append(w)\n",
    "                cur_tokens += tw\n",
    "            if cur:\n",
    "                chunks.append(\" \".join(cur))\n",
    "    return chunks\n",
    "\n",
    "chunks = smart_chunk(doc_text, max_tokens=450, overlap=60)\n",
    "\n",
    "def embed_batch(texts):\n",
    "    vecs = []\n",
    "    for t in texts:\n",
    "        e = ollama.embeddings(model=EMBED_MODEL, prompt=t)[\"embedding\"]\n",
    "        vecs.append(np.array(e, dtype=np.float32))\n",
    "    arr = np.vstack(vecs) if vecs else np.zeros((0,1), dtype=np.float32)\n",
    "    # normalize for cosine\n",
    "    arr /= (np.linalg.norm(arr, axis=1, keepdims=True) + 1e-9)\n",
    "    return arr\n",
    "\n",
    "chunk_vecs = embed_batch(chunks)\n",
    "\n",
    "def retrieve(query: str, k=5):\n",
    "    q = np.array(ollama.embeddings(model=EMBED_MODEL, prompt=query)[\"embedding\"], dtype=np.float32)\n",
    "    q /= (np.linalg.norm(q) + 1e-9)\n",
    "    sims = chunk_vecs @ q\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    return [(float(sims[i]), chunks[i]) for i in idx]\n",
    "\n",
    "\n",
    "#ask next question using retrieved context based on the last candidate utterance\n",
    "#and (if available) the last examiner question to maintain thread\n",
    "def examiner_question(history, k_ctx=4, new_case=False):\n",
    "    has_user = any(m[\"role\"] == \"user\" for m in history)\n",
    "\n",
    "    if new_case or not has_user:\n",
    "        # Fresh start: retrieve generic opening context and *do not* reference prior dialogue\n",
    "        ctx = retrieve(\"opening vignette general surgery\", k=k_ctx)\n",
    "        context_block = \"\\n\\n---\\n\".join([c for _, c in ctx]) if ctx else \"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_EXAMINER},\n",
    "            {\"role\": \"user\", \"content\":\n",
    "                \"CONTEXT:\\n\"\n",
    "                f\"{context_block}\\n\\n\"\n",
    "                \"Start a NEW, self-contained case. Provide an opening vignette \"\n",
    "                \"(age/sex, chief complaint, brief vitals, 1–2 key positives/negatives), \"\n",
    "                \"then ask exactly ONE initial question. Do NOT say 'continue' or reference prior dialogue.\"\n",
    "            },\n",
    "        ]\n",
    "        return ollama.chat(model=LLM, messages=messages)[\"message\"][\"content\"].strip()\n",
    "\n",
    "    \n",
    "    last_user = next((m[\"content\"] for m in reversed(history) if m[\"role\"] == \"user\"), \"acute appendicitis adult\")\n",
    "    last_exam_q = next((m[\"content\"] for m in reversed(history) if m[\"role\"] == \"assistant\"), \"\")\n",
    "    retrieval_query = (last_exam_q + \" \" + last_user).strip()\n",
    "\n",
    "    ctx = retrieve(retrieval_query, k=k_ctx)\n",
    "    context_block = \"\\n\\n---\\n\".join([c for _, c in ctx]) if ctx else \"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_EXAMINER},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"CONTEXT:\\n\"\n",
    "                f\"{context_block}\\n\\n\"\n",
    "                f\"CANDIDATE PREVIOUS: {last_user}\\n\"\n",
    "                \"Now ask exactly ONE next oral-boards question. Do not reveal answers.\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    out = ollama.chat(model=LLM, messages=messages)[\"message\"][\"content\"].strip()\n",
    "    return out\n",
    "\n",
    "\n",
    "def examiner_hint(history):\n",
    "    last_user = next((m[\"content\"] for m in reversed(history) if m[\"role\"] == \"user\"), \"\")\n",
    "    ctx = retrieve(last_user or \"acute appendicitis adult\", k=3)\n",
    "    context_block = \"\\n\\n---\\n\".join([c for _, c in ctx]) if ctx else \"\"\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\": SYSTEM_EXAMINER},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "         f\"CONTEXT:\\n{context_block}\\n\"\n",
    "         f\"Candidate said: {last_user}\\nProvide ONE short hint (<=25 words).\"}\n",
    "    ]\n",
    "    return ollama.chat(model=LLM, messages=messages)[\"message\"][\"content\"].strip()\n",
    "\n",
    "def examiner_grade(history):\n",
    "    last_user = next((m[\"content\"] for m in reversed(history) if m[\"role\"] == \"user\"), \"\")\n",
    "    ctx = retrieve(last_user or \"evaluation rubric\", k=3)\n",
    "    context_block = \"\\n\\n---\\n\".join([c for _, c in ctx]) if ctx else \"\"\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\": SYSTEM_EXAMINER},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "         f\"CONTEXT:\\n{context_block}\\n\"\n",
    "         f\"Evaluate the candidate's last answer:\\n\\\"\\\"\\\"{last_user}\\\"\\\"\\\"\\n\"\n",
    "         \"Return: score 0–10, 2–3 bullet strengths, 2–3 bullet deficits, pass/fail with rationale tied to case facts.\"}\n",
    "    ]\n",
    "    return ollama.chat(model=LLM, messages=messages)[\"message\"][\"content\"].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d721d835-0074-4a3c-853e-34dbe9a705e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim():\n",
    "    print(\"Oral Boards Simulator\\n\"\n",
    "          \"Commands: /start, /next, /hint, /grade, /end\\n\"\n",
    "          \"You are the CANDIDATE. The AI is the EXAMINER.\\n\")\n",
    "    history = []\n",
    "    started = False\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_in = input(\"> \").strip()\n",
    "\n",
    "            if user_in.lower() == \"/end\":\n",
    "                print(\"Session ended.\")\n",
    "                break\n",
    "\n",
    "            if user_in.lower() == \"/start\":\n",
    "                started = True\n",
    "                history = []\n",
    "                q = examiner_question(history, new_case=True)\n",
    "                print(f\"\\nExaminer: {q}\\n\")\n",
    "                history.append({\"role\":\"assistant\",\"content\":q})\n",
    "                continue\n",
    "\n",
    "            if not started:\n",
    "                print('Type \"/start\" to begin.')\n",
    "                continue\n",
    "\n",
    "            if user_in.lower() == \"/next\":\n",
    "                # Advance flow: simply ask next question; retrieval uses last turn\n",
    "                q = examiner_question(history)\n",
    "                print(f\"\\nExaminer: {q}\\n\")\n",
    "                history.append({\"role\":\"assistant\",\"content\":q})\n",
    "                continue\n",
    "\n",
    "            if user_in.lower() == \"/hint\":\n",
    "                h = examiner_hint(history)\n",
    "                print(f\"\\nHint: {h}\\n\")\n",
    "                continue\n",
    "\n",
    "            if user_in.lower() == \"/grade\":\n",
    "                g = examiner_grade(history)\n",
    "                print(f\"\\nGrading:\\n{g}\\n\")\n",
    "                continue\n",
    "\n",
    "            # Candidate's answer\n",
    "            history.append({\"role\":\"user\",\"content\":user_in})\n",
    "            if len(history) > 24:\n",
    "                history = history[-24:]  # keep context compact\n",
    "\n",
    "            # Next examiner question\n",
    "            q = examiner_question(history)\n",
    "            print(f\"\\nExaminer: {q}\\n\")\n",
    "            history.append({\"role\":\"assistant\",\"content\":q})\n",
    "\n",
    "        except (KeyboardInterrupt, EOFError):\n",
    "            print(\"\\nSession interrupted.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "343d941d-264d-4bcc-9c0b-4933109e0307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-02 17:32:37] Loading baseCase from: C:\\Users\\jmcam\\OneDrive\\Desktop\\SoftwareDocuments\\baseCase.md\n",
      "Oral Boards Simulator\n",
      "Commands: /start, /next, /hint, /grade, /end\n",
      "You are the CANDIDATE. The AI is the EXAMINER.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  /start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examiner: This is the beginning of the exam:\n",
      "\n",
      "You are presented with a 23-year-old male, Mr. David Miller, who presents to the Emergency Department complaining of right lower quadrant pain that began approximately 18 hours prior. He reports the pain is constant, rated 8/10, and has been worsening over the last 6 hours. He denies fever, chills, nausea, or vomiting. Initial vitals are: Temperature 98.6°F (37°C), Heart Rate 110 bpm, Blood Pressure 130/80 mmHg, Respiratory Rate 18 breaths/min, Oxygen Saturation 98% on room air. Abdominal exam reveals mild tenderness to palpation in the right lower quadrant with guarding. Bowel sounds are normoactive. He has no known allergies and takes no regular medications.\n",
      "\n",
      "Given this presentation, what is the first step in your management?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I would prescribe 5g of ibuprofen taken orally every 6 hours and send them home.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examiner: Okay, let's proceed.\n",
      "\n",
      "**Examiner:** The patient has now been discharged home on oral antibiotics and follow-up with his primary care physician. Six weeks later, he returns to your clinic complaining of recurrent right lower quadrant pain. He denies fever or nausea. Physical exam reveals tenderness at the McBurney's point. What is the most likely diagnosis and what is the next step in management?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  /grade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grading:\n",
      "Okay, here’s my evaluation of the candidate’s last answer:\n",
      "\n",
      "**Score: 2/10**\n",
      "\n",
      "**Bullet Strengths:**\n",
      "\n",
      "*   **Recognition of Pain:** The candidate acknowledges the patient likely has pain, which is a crucial initial consideration.\n",
      "\n",
      "\n",
      "**Bullet Deficits:**\n",
      "\n",
      "*   **Lack of Specificity & Inadequate Analgesia:** Prescribing “5g of ibuprofen” is entirely insufficient. The patient likely has a significant inflammatory response and will require higher doses and potentially other analgesics.  This demonstrates a failure to consider the magnitude of the problem.\n",
      "*   **Ignoring IV Access & Supportive Care:** The initial instructions (as presented in the case) explicitly state “Establish IV access…” This answer completely disregards the need for intravenous fluids, antiemetics, and potentially antibiotics – all vital components of initial management.\n",
      "*   **Failure to Address Underlying Cause:** The answer doesn’t address the bacterial infection that is causing the patient’s symptoms. Simply providing pain relief without addressing the infection is negligent.\n",
      "\n",
      "**Pass/Fail:** Fail\n",
      "\n",
      "**Rationale:** This answer is fundamentally deficient. It demonstrates a critical failure to understand the basic principles of initial surgical management, particularly in the context of an acute abdominal process like appendicitis. The candidate’s response highlights a lack of clinical judgment and a failure to prioritize patient safety. The provided answer completely ignores the established preoperative optimization steps and the need for comprehensive treatment of the underlying infection.\n",
      "\n",
      "\n",
      "Session interrupted.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Loading baseCase from: {BASE_PATH}\")\n",
    "    run_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595f356-875f-483c-9bdb-923109f442cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for later use and was just for testing text to speach\n",
    "\n",
    "\n",
    "def speak_text(text: str, out_path: str = \"answer.wav\", speaker: str | None = None):\n",
    "    kwargs = {}\n",
    "    if speaker is not None: #multi-speaker models\n",
    "        kwargs[\"speaker\"]=speaker\n",
    "    tts.tts_to_file(text=text, file_path=out_path, **kwargs)\n",
    "    return ipd.Audio(out_path)\n",
    "\n",
    "def chat_and_speak(prompt: str, out_path=\"answer.wav\", speaker=None):\n",
    "    resp = ollama.chat(model=LLM, messages=[{\"role\":\"user\",\"content\": prompt}])\n",
    "    text = resp[\"message\"][\"content\"]\n",
    "    print(\"LLM:\", text)\n",
    "    return speak_text(text, out_path, speaker)\n",
    "\n",
    "# use it:\n",
    "chat_and_speak(\"Give three key symptoms of diverticulitis. No disclaimers, no special characters, give short sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe8765ca-850b-4380-ac8c-4fc28adddbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: C:\\Users\\jmcam\\.venv-tts\\Scripts\\python.exe\n",
      "Found git at: C:\\Program Files\\Git\\cmd\\git.exe\n",
      "git --version -> git version 2.51.0.windows.1\n",
      "        1 file(s) copied.C:\\Users\\jmcam\\Documents\\ENGR-498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'OralBoardAI.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main e36bad1] Add OralBoardAI notebook\n",
      " 1 file changed, 35 insertions(+), 162 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Jonah-Camacho/ENGR-498.git\n",
      " ! [rejected]        main -> main (fetch first)\n",
      "error: failed to push some refs to 'https://github.com/Jonah-Camacho/ENGR-498.git'\n",
      "hint: Updates were rejected because the remote contains work that you do not\n",
      "hint: have locally. This is usually caused by another repository pushing to\n",
      "hint: the same ref. If you want to integrate the remote changes, use\n",
      "hint: 'git pull' before pushing again.\n",
      "hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "# Note: Run to commit the file to the git\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "import os, sys, subprocess, glob\n",
    "\n",
    "# Candidate install locations (system + per-user)\n",
    "cands = [\n",
    "    r\"C:\\Program Files\\Git\\cmd\\git.exe\",\n",
    "    r\"C:\\Program Files (x86)\\Git\\cmd\\git.exe\",\n",
    "    r\"%LOCALAPPDATA%\\Programs\\Git\\cmd\\git.exe\",\n",
    "]\n",
    "cands = [os.path.expandvars(p) for p in cands]\n",
    "\n",
    "# Also try to discover git.exe if installed in a nonstandard place\n",
    "cands += glob.glob(r\"C:\\Program Files\\Git\\cmd\\git.exe\")\n",
    "cands += glob.glob(os.path.expandvars(r\"%LOCALAPPDATA%\\Programs\\Git\\cmd\\git.exe\"))\n",
    "\n",
    "found = next((p for p in cands if os.path.exists(p)), None)\n",
    "print(\"Kernel:\", sys.executable)\n",
    "print(\"Found git at:\", found)\n",
    "\n",
    "if found:\n",
    "    git_cmd = os.path.dirname(found)\n",
    "    git_bin = git_cmd.replace(r\"\\cmd\", r\"\\bin\")\n",
    "    os.environ[\"PATH\"] += \";\" + git_cmd + \";\" + git_bin\n",
    "    try:\n",
    "        print(\"git --version ->\", subprocess.check_output([\"git\",\"--version\"], text=True).strip())\n",
    "    except Exception as e:\n",
    "        print(\"Tried to add PATH but still failing:\", e)\n",
    "else:\n",
    "    print(\"Could not locate git.exe automatically. If you know the path, run:\")\n",
    "    print(r'import os; os.environ[\"PATH\"] += r\";C:\\Path\\To\\Git\\cmd;C:\\Path\\To\\Git\\bin\"')\n",
    "!git remote set-url origin https://github.com/Jonah-Camacho/ENGR-498.git\n",
    "!copy /Y \"C:\\Users\\jmcam\\OralBoardAI.ipynb\" \"C:\\Users\\jmcam\\Documents\\ENGR-498\\OralBoardAI.ipynb\"\n",
    "%cd \"C:\\Users\\jmcam\\Documents\\ENGR-498\"\n",
    "!git add -- \"OralBoardAI.ipynb\"\n",
    "!git commit -m \"Add OralBoardAI notebook\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d26bcd95-c45c-4557-a27d-75a575de3b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmcam\\Documents\\ENGR-498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/Jonah-Camacho/ENGR-498\n",
      "   0e0eee7..5dd02a8  main       -> origin/main\n",
      "From https://github.com/Jonah-Camacho/ENGR-498\n",
      " * branch            main       -> FETCH_HEAD\n",
      "Rebasing (1/1)\n",
      "Successfully rebased and updated refs/heads/main.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Jonah-Camacho/ENGR-498.git\n",
      "   5dd02a8..8ad2df9  main -> main\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\jmcam\\Documents\\ENGR-498\"\n",
    "!git config core.autocrlf true\n",
    "!git fetch origin\n",
    "!git pull --rebase origin main\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2f81b-9968-4107-9034-0ef05f339850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tts)",
   "language": "python",
   "name": "tts310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
